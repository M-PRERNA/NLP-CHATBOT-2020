{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "chatybot.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOk9/84iLONhPcZk2Tiwime",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/M-PRERNA/NLP-CHATBOT-2020/blob/main/chatybot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwYfXlRRXDpj"
      },
      "source": [
        "# **PART 1: NLP**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvmXw66UEQqa"
      },
      "source": [
        "# importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHr2mCfIEvc_"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import re\n",
        "import time\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OXZcsI4ENG8"
      },
      "source": [
        "# importing the data sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LiFpHQhGHcJf"
      },
      "source": [
        "lines = open('movie_lines.txt', encoding='utf-8', errors='ignore').read().split('\\n')\n",
        "conversations = open('movie_conversations.txt', encoding='utf-8', errors='ignore').read().split('\\n')\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_kOlYsCD-9e"
      },
      "source": [
        "# creating a dictionary and maps each line with its id\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKm7e3EzJ4k6"
      },
      "source": [
        "id2line = {}\n",
        "for line in lines:\n",
        "  _line = line.split(' +++$+++ ')\n",
        "  if len(_line)==5:\n",
        "    id2line[_line[0]]=_line[4] "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FoQrCByQE7Mj"
      },
      "source": [
        "# creating a list of all the conversations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaVVBDBtK6d-"
      },
      "source": [
        "conversation_ids=[]\n",
        "for conversation in conversations[:-1]: \n",
        "  _conversation = conversation.split(' +++$+++ ')[-1][1:-1].replace(\"'\",\"\").replace(\" \",\"\")#to remove the squarebrackets which are indexed as 0 and -1 and removing the single quotes\n",
        "  conversation_ids.append(_conversation.split(\",\"))\n",
        "  # here underscore _ means its a temporary variable\n",
        "\n",
        "# conversation_ids"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnoHTLqNL-dp"
      },
      "source": [
        "# get separately the question and the answers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmNNrMJ_MNDW"
      },
      "source": [
        "questions = []\n",
        "answers = []\n",
        "\n",
        "for conversation in conversation_ids :\n",
        "  for i in range (len(conversation)-1):\n",
        "    questions.append(id2line[conversation[i]])\n",
        "    answers.append(id2line[conversation[i+1]])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hX9xXUIcXC1T"
      },
      "source": [
        "# Doing a first cleaning of the text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYsw8ZmsXI6i"
      },
      "source": [
        "def clean_text(text):\n",
        "  text = text.lower()\n",
        "  # using regex to clean\n",
        "  text = re.sub(r\"i'am\",\"i am\",text)\n",
        "  text = re.sub(r\"he's\",\"he is\",text)\n",
        "  text = re.sub(r\"she's\",\"she is\",text)\n",
        "  text = re.sub(r\"there's\",\"there is\",text)\n",
        "  text = re.sub(r\"who's\",\"who is\",text)\n",
        "  text = re.sub(r\"where's\",\"where is\",text)\n",
        "  text = re.sub(r\"what's\",\"what's\",text)\n",
        "  text = re.sub(r\"\\'ll\",\" will\",text)\n",
        "  text = re.sub(r\"\\'ve\",\" have\",text)\n",
        "  text = re.sub(r\"\\'d\",\" would\",text)\n",
        "  text = re.sub(r\"\\'ll\",\" will\",text)\n",
        "  text = re.sub(r\"\\'re\",\" are\",text)\n",
        "  text = re.sub(r\"won't\",\"will not\",text)\n",
        "  text = re.sub(r\"shouldn't\",\"should not\",text)\n",
        "  text = re.sub(r\"hasn't\",\"has not\",text)\n",
        "  text = re.sub(r\"can't\",\"can not\",text)\n",
        "  text = re.sub(r\"don't\",\"do not\",text)\n",
        "  text = re.sub(r\"isn't\",\"is not\",text)\n",
        "  text = re.sub(r\"[-()\\\"{}/@#%;<>:*$+=~`?.,|]\",\"\",text)\n",
        "  return text\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5WmeSp9c6UQ"
      },
      "source": [
        "# cleaning the questions and answers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9NyTN7Mc-Jm"
      },
      "source": [
        "clean_questions =[]\n",
        "for question in questions:\n",
        "  clean_questions.append(clean_text(question))\n",
        "\n",
        "clean_answers =[]\n",
        "for answer in answers:\n",
        "  clean_answers.append(clean_text(answer))\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0iJ-0WZg0O7"
      },
      "source": [
        "## process to remove the not so frequent words from the data sets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0zeVuwmgg1z"
      },
      "source": [
        "# creating a dictionary that maps each word to its number of occurences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kgpGlH3elYU"
      },
      "source": [
        "word2count = {}\n",
        "for question in clean_questions:\n",
        "  for word in question.split():\n",
        "    if word not in word2count:\n",
        "      word2count[word]=1\n",
        "    else:\n",
        "      word2count[word] +=1\n",
        "\n",
        "for answer in clean_answers:\n",
        "  for word in answer.split():\n",
        "    if word not in word2count:\n",
        "      word2count[word]=1\n",
        "    else:\n",
        "      word2count[word] +=1"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puSFgOf8fnz-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-v9b1Mr2kwMe"
      },
      "source": [
        "#creating two dictionaries that map the question words and answer words to a unique integer\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mve7VDwulEF1"
      },
      "source": [
        "threshold = 20\n",
        "questionsword2int ={}\n",
        "word_number = 0\n",
        "for word,count in word2count.items():\n",
        "  if count>=threshold:\n",
        "    questionsword2int[word]=word_number\n",
        "    word_number +=1\n",
        "# includes only 95% of the most frequent words\n",
        "answersword2int ={}\n",
        "word_number = 0\n",
        "for word,count in word2count.items():\n",
        "  if count>=threshold:\n",
        "    answersword2int[word]=word_number\n",
        "    word_number +=1\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gj_lxgGPsydh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w11zdBDw7coV"
      },
      "source": [
        "# adding the last tokens to the two dictionaries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtvXZbEQ7jaa"
      },
      "source": [
        "# # these special tokens are used in seq2seq models in python \n",
        "# GO - the same as <start> on the picture below - the first token which is fed to the decoder along with the though vector in order to start generating tokens of the answer\n",
        "# EOS - \"end of sentence\" - the same as <end> on the picture below - as soon as decoder generates this token we consider the answer to be complete (you can't use usual punctuation marks for this purpose cause their meaning can be different)\n",
        "# UNK - \"unknown token\" - is used to replace the rare words that did not fit in your vocabulary. So your sentence My name is guotong1988 will be translated into My name is _unk_.\n",
        "# PAD - your GPU (or CPU at worst) processes your training data in batches and all the sequences in your batch should have the same length. If the max length of your sequence is 8, your sentence My name is guotong1988 will be padded from either side to fit this length: My name is guotong1988 _pad_ _pad_ _pad_ _pad_\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tmj9aAo174S9"
      },
      "source": [
        "tokens=['<PAD>','<EOS>','<OUT>','<SOS>']\n",
        "for token in tokens :\n",
        "  questionsword2int[token]=len(questionsword2int)+1\n",
        "\n",
        "for token in tokens :\n",
        "  answersword2int[token]=len(answersword2int)+1"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEHTyPf59sgJ"
      },
      "source": [
        "# creating an inverse map of the answers dictionary for mapping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWNg4J0c93Xx"
      },
      "source": [
        "###### note the trick to inverse a dictionary\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-Iv_sb69rZO"
      },
      "source": [
        "answersint2word = {w_i: w for w, w_i in answersword2int.items()}"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jh91O-bG_0-i"
      },
      "source": [
        "# answersint2word"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TqnN4SiAh57"
      },
      "source": [
        "# to add the end of string token to the end of every answer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGeJ5w_1_3kY"
      },
      "source": [
        "for i in range (len(clean_answers)):\n",
        "  clean_answers[i] += ' <EOS>'"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8c4BAr3mDDvv"
      },
      "source": [
        "# translating all the questions and answers into integers\n",
        "# and replacing all the words that were filtered by OUT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFvqt0-GDDDE"
      },
      "source": [
        "questions_to_int = []\n",
        "for question in clean_questions:\n",
        "  ints =[]\n",
        "  for word in question.split():\n",
        "    if word not in questionsword2int:\n",
        "      ints.append(questionsword2int['<OUT>'])\n",
        "    else:\n",
        "      ints.append(questionsword2int[word])\n",
        "  questions_to_int.append(ints)\n",
        "\n",
        "\n",
        "answers_to_int = []\n",
        "for answer in clean_answers:\n",
        "  ints =[]\n",
        "  for word in answer.split():\n",
        "    if word not in answersword2int:\n",
        "      ints.append (answersword2int ['<OUT>'])\n",
        "    else:\n",
        "      ints.append(answersword2int[word])\n",
        "  answers_to_int.append(ints)\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjfMENjwJiIT"
      },
      "source": [
        "# sorting questions and answers based upon the length of the questions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DP9cN2ykJOwE"
      },
      "source": [
        "sorted_clean_questions=[]\n",
        "sorted_clean_answers = []\n",
        "for length in range (1,25+1):\n",
        "  for i in enumerate (questions_to_int):\n",
        "    if len(i[1])==length:\n",
        "      sorted_clean_questions.append(questions_to_int[i[0]])\n",
        "      sorted_clean_answers.append(answers_to_int[i[0]])\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJDRuYCNRh3P"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWDlI7jaXPwc"
      },
      "source": [
        "# **PART 2: BUILDING THE SEQ2SEQ MODEL**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4z146ngXg29"
      },
      "source": [
        " # Creating placeholders for the inputs and the targets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rj4PN8v4XZjS"
      },
      "source": [
        "def model_inputs():\r\n",
        "  inputs = tf.placeholder(tf.int32, [None,None],name = 'input')\r\n",
        "  # the tf.int32->is the tensorflow datatype [None,None]->the dimensions of the inputs matrix name='input' specifies the input of the place holder\r\n",
        "  targets = tf.placeholder(tf.int32, [None,None],name = 'target') #the answers are the targets\r\n",
        "  # which we would compare with our chatbot models\r\n",
        "  lr = tf.placeholder(tf.float32, name = 'learning_rate')\r\n",
        "  keep_prob = tf.placeholder(tf.float32, name = 'keep_prob')\r\n",
        "  return inputs, targets, lr, keep_prob\r\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bU42baEZpTaM"
      },
      "source": [
        "# before putting the inputs into the encoder of our sequence to sequence models \r\n",
        "# we need to first preprocess them so that they are accessible by the encoder\r\n",
        "def preprocess_targets(targets, word2int, batch_size):\r\n",
        "  left_side = tf.fill([batch_size,1],word2int['<SOS>'])\r\n",
        "  right_side = tf.strided_slice(targets, [0,0], [batch_size, -1], [1,1])\r\n",
        "  preprocessed_targets = tf.concat ([left_side,right_side],1)\r\n",
        "  return preprocessed_targets"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJ7zloMrxpv1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2y3N3OFxy3a"
      },
      "source": [
        "# Architecture of Seq2Seq model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GX40ik3rx5qK"
      },
      "source": [
        "# Creating the encoder RNN layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QaG7ct4x4QT"
      },
      "source": [
        "def encoder_rnn_layer(rnn_inputs, rnn_size, num_layers, keep_prob, sequence_length):\r\n",
        "  lstm = tf.contrib.rnn.BasicLSTMCell(rnn_size)\r\n",
        "# new object of the dropout wrapper class because 20% of the neurons are non-existent during the training\r\n",
        "  lstm_dropout = "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}